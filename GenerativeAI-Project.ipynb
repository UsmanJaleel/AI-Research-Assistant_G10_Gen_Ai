{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9469304-d77b-423d-bc0a-b16aa490955d",
   "metadata": {},
   "source": [
    "# AI Research Assistant: Cross-Document Knowledge Synthesis\n",
    "\n",
    "## Project Overview\n",
    "This project implements a Generative AI based research assistant designed to help students and\n",
    "researchers work more effectively with academic materials such as lecture slides and research\n",
    "papers in PDF format.\n",
    "\n",
    "Unlike traditional PDF question answering systems, this assistant focuses on cross document\n",
    "retrieval and knowledge synthesis. It retrieves relevant information from multiple documents\n",
    "and generates unified, coherent answers grounded strictly in the uploaded sources.\n",
    "\n",
    "The system is implemented and demonstrated using a Jupyter Notebook, allowing full\n",
    "transparency of intermediate steps such as document chunking, retrieval results, and synthesized\n",
    "answers.\n",
    "\n",
    "---\n",
    "\n",
    "## User Interface\n",
    "\n",
    "**Selected Interface:** Jupyter Notebook\n",
    "\n",
    "The Jupyter Notebook interface fits the workflow of students and researchers who frequently use\n",
    "notebooks for learning, experimentation, and analysis. It enables step by step inspection of the\n",
    "retrieval, synthesis, and generation processes, making the system both educational and practical.\n",
    "This design supports exploratory research, debugging, and reproducibility.\n",
    "\n",
    "---\n",
    "\n",
    "## Group Information\n",
    "\n",
    "**Course:** Generative AI  \n",
    "**Group Number:** Group 10  \n",
    "\n",
    "**Group Members:**\n",
    "- Hamza Rashid\n",
    "- Jaleel Usman  \n",
    "- Raja Wajahat Ali  \n",
    "- Maqsood Asim  \n",
    "- Zai Zohaib Sultan Yousuf  \n",
    "\n",
    "---\n",
    "\n",
    "## Notebook Structure\n",
    "\n",
    "1. Load and preprocess academic PDF documents  \n",
    "2. Chunk documents for fine grained retrieval  \n",
    "3. Generate embeddings using TF IDF  \n",
    "4. Perform cross document semantic retrieval  \n",
    "5. Synthesize knowledge across multiple sources  \n",
    "6. Answer user questions using a local LLM  \n",
    "7. Provide an interactive notebook based interface  \n",
    "\n",
    "This notebook represents the final prototype submitted as part of the group project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3dbd2d-cff5-439c-903a-84c05ec39169",
   "metadata": {},
   "source": [
    "## Environment Setup and Libraries\n",
    "\n",
    "This cell installs and imports all required libraries used throughout the notebook.\n",
    "All dependencies are declared upfront to ensure reproducibility and transparency.\n",
    "\n",
    "The project relies on lightweight PDF parsing, classical text retrieval techniques,\n",
    "and a local large language model for answer generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e11e3025-7e4a-4e3d-9260-92c1ede1bd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# PDF processing\n",
    "from pypdf import PdfReader\n",
    "\n",
    "# Text processing and retrieval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f17b8bb-ecd8-4d97-aff7-7b55f996a20c",
   "metadata": {},
   "source": [
    "## Loading Academic PDF Documents\n",
    "\n",
    "### Project Plan Reference: 5.1.2 Data\n",
    "\n",
    "In this step, we load multiple academic PDF documents that form the system‚Äôs\n",
    "knowledge base. PDFs are the primary knowledge artifacts used by students and\n",
    "researchers, such as lecture slides and research papers.\n",
    "\n",
    "Each document is stored together with its source filename to preserve minimal\n",
    "context for later analysis and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "318afa4e-02cb-4aa8-87a1-d4ad2e758df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 9 0 (offset 0)\n",
      "Ignoring wrong pointing object 11 0 (offset 0)\n",
      "Ignoring wrong pointing object 13 0 (offset 0)\n",
      "Ignoring wrong pointing object 29 0 (offset 0)\n",
      "Ignoring wrong pointing object 53 0 (offset 0)\n",
      "Ignoring wrong pointing object 95 0 (offset 0)\n",
      "Ignoring wrong pointing object 128 0 (offset 0)\n",
      "Ignoring wrong pointing object 130 0 (offset 0)\n",
      "Ignoring wrong pointing object 166 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 3 PDF documents.\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "pdf_folder = \"pdfs\"\n",
    "\n",
    "for file in os.listdir(pdf_folder):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        reader = PdfReader(os.path.join(pdf_folder, file))\n",
    "        full_text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                full_text += text + \"\\n\"\n",
    "\n",
    "        documents.append({\n",
    "            \"content\": full_text,\n",
    "            \"source\": file\n",
    "        })\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(documents)} PDF documents.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0773e4cb-c8fc-4455-8254-539bf5c7b4e1",
   "metadata": {},
   "source": [
    "## Chunking Documents\n",
    "\n",
    "### Project Plan Reference: 5.1.2 Data ‚Äì Granularity\n",
    "\n",
    "Academic PDFs are long documents containing multiple concepts. To enable fine-grained\n",
    "semantic retrieval, each document is split into smaller overlapping chunks.\n",
    "\n",
    "Chunking improves retrieval accuracy and enables cross-document comparison at the\n",
    "concept level rather than entire documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "772d2d79-c341-4e0f-852f-64ee56fa25eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created 86 text chunks from PDFs.\n"
     ]
    }
   ],
   "source": [
    "def chunk_text(text, chunk_size=800, overlap=200):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    text_length = len(text)\n",
    "\n",
    "    while start < text_length:\n",
    "        end = start + chunk_size\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(chunk)\n",
    "        start = end - overlap\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# Create chunks from all documents\n",
    "chunks = []\n",
    "\n",
    "for doc in documents:\n",
    "    text_chunks = chunk_text(doc[\"content\"])\n",
    "    for chunk in text_chunks:\n",
    "        chunks.append({\n",
    "            \"page_content\": chunk,\n",
    "            \"metadata\": {\"source\": doc[\"source\"]}\n",
    "        })\n",
    "\n",
    "print(f\"‚úÖ Created {len(chunks)} text chunks from PDFs.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa8f01a-e5a8-48c9-9ac3-3860284e3c80",
   "metadata": {},
   "source": [
    "## Embedding Documents for Semantic Retrieval (Offline)\r\n",
    "\r\n",
    "### Project Plan Reference: 5.1.4 Solution ‚Äì Retrieve\r\n",
    "\r\n",
    "Due to API quota limitations, we implement an **offline embedding approach**\r\n",
    "using TF-IDF vectorization. While simpler than neural embeddings, TF-IDF provides\r\n",
    "a strong baseline for semantic retrieval and ensures full reproducibility without\r\n",
    "external dependencies.\r\n",
    ".\r\n",
    " stages.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc1a44c5-0e17-4333-ab23-147a6615b4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ TF-IDF embeddings created successfully.\n",
      "üìÑ Embedded chunks: 86\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# Prepare texts\n",
    "texts = [c[\"page_content\"] for c in chunks]\n",
    "\n",
    "# Create TF-IDF embeddings\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    stop_words=\"english\"\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(texts).toarray()\n",
    "\n",
    "print(\"‚úÖ TF-IDF embeddings created successfully.\")\n",
    "print(f\"üìÑ Embedded chunks: {X.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060224df-f88e-4a90-9b5c-b969da2564c4",
   "metadata": {},
   "source": [
    "## Cross-Document Retrieval\r\n",
    "\r\n",
    "### Project Plan Reference: 5.1.3 The Problem ‚Äì Retrieval & Synthesis\r\n",
    "\r\n",
    "In this step, the system retrieves relevant passages related to a research query\r\n",
    "from **multiple documents** using cosine similarity. This demonstrates that the\r\n",
    "system supports cross-document retrieval rather than single-document lookup.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb6669cb-bb1e-466c-a32c-869ecee8edcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Retrieved passages from multiple documents:\n",
      "\n",
      "1. Source: 2025.10.29 - Transformer.pdf\n",
      "   k at the  encoder and decoder  blocks.  #2A6495 The attention mechanismThe cornerstone of the transformer's ability to capture context. ùê¥ùë°ùë°ùëíùëõùë°ùëñùëúùëõùëÑ,ùêæ,ùëâ=ùë†ùëúùëìùë°ùëöùëéùë•ùëÑùêæùëá ùëëùëò ùëâ #2A6495 dragon #2A6495 The dragon #2A6495 The cute dragon #2A6495 The dragoncute green  #2A6495 Attention Mechanism An example of the...\n",
      "\n",
      "2. Source: Applied GenAI II.pdf\n",
      "   ion Reflect Analyze thinking patterns and knowledge gaps Accessing LLMs HuggingFace  Types of Pre-Trained Models 1 Foundation Models (= Base Models) Usually trained for next token prediction / text completion 2 Fine-Tuned Models Specialised for specific tasks: Instruct models follow instructions on ...\n",
      "\n",
      "3. Source: 2025.10.29 - Transformer.pdf\n",
      "   uch  attention tokens should pay to each other. Scale the dot product to avoid ensure stable  gradient flow. Create attention weights using the softmax function  to normalise embeddings.  Multiply attention weights by the Value matrix Optionally hide future tokens to ensure that token  predictions d...\n",
      "\n",
      "4. Source: Applied GenAI I.pdf\n",
      "   ownstream tasks. Frontier models represent the most advanced and powerful  foundation models, pushing the boundaries of AI capabilities at any given time. AI Model Taxonomy: Openness 1 Closed-Source Models Proprietary models where weights, inference code, and training data remain confidential. Acces...\n",
      "\n",
      "5. Source: 2025.10.29 - Transformer.pdf\n",
      "   , keys and values. The goal of the attention mechanism is to compute and ingest how much and how each token  should influence the representation (‚Äúmeaning‚Äù) of every other token within the input sequence.  #2A6495 Mathematical intuition behind queries, keys and values. The dot product can be used to...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Define a research query\n",
    "query = \"attention mechanisms in transformer models\"\n",
    "\n",
    "# Embed the query using the same TF-IDF vectorizer\n",
    "query_vec = vectorizer.transform([query]).toarray()\n",
    "\n",
    "# Compute cosine similarity between query and all chunks\n",
    "similarity_scores = cosine_similarity(query_vec, X)[0]\n",
    "\n",
    "# Retrieve top-k most relevant chunks\n",
    "k = 5\n",
    "top_indices = np.argsort(similarity_scores)[-k:][::-1]\n",
    "\n",
    "print(\"üîç Retrieved passages from multiple documents:\\n\")\n",
    "\n",
    "for rank, idx in enumerate(top_indices, start=1):\n",
    "    source = chunks[idx][\"metadata\"][\"source\"]\n",
    "    preview = chunks[idx][\"page_content\"][:300].replace(\"\\n\", \" \")\n",
    "    print(f\"{rank}. Source: {source}\")\n",
    "    print(f\"   {preview}...\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd4be2a-d8eb-4687-81c4-e1544d3ef2c1",
   "metadata": {},
   "source": [
    "## Knowledge Synthesis\n",
    "\n",
    "In this step, the system synthesizes information retrieved from multiple documents\n",
    "into a coherent overview. Instead of presenting isolated text passages, related\n",
    "ideas from different sources are combined to help users understand the topic at a\n",
    "higher level of abstraction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "771106d6-daff-42b0-84ab-f89e7e607250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Synthesized Knowledge:\n",
      "\n",
      "Source: 2025.10.29 - Transformer.pdf\n",
      "- k at the  encoder and decoder  blocks.  #2A6495 The attention mechanismThe cornerstone of the transformer's ability to capture context. ùê¥ùë°ùë°ùëíùëõùë°ùëñùëúùëõùëÑ,ùêæ,ùëâ=ùë†ùëúùëìùë°ùëöùëéùë•ùëÑùêæùëá ùëëùëò ùëâ #2A6495 dragon #2A6495 The dragon #2A6495 The cute dragon #2A6495 The dragoncute green  #2A6495 Attention Mechanism An example of the exchange of attention in a group of people eager \n",
      "\n",
      "Source: Applied GenAI II.pdf\n",
      "- ion Reflect Analyze thinking patterns and knowledge gaps Accessing LLMs HuggingFace  Types of Pre-Trained Models 1 Foundation Models (= Base Models) Usually trained for next token prediction / text completion 2 Fine-Tuned Models Specialised for specific tasks: Instruct models follow instructions on a single prompt often work well in conversations C\n",
      "- uch  attention tokens should pay to each other. Scale the dot product to avoid ensure stable  gradient flow. Create attention weights using the softmax function  to normalise embeddings.  Multiply attention weights by the Value matrix Optionally hide future tokens to ensure that token  predictions depend only on previous tokens. Project result to o\n",
      "\n",
      "Source: Applied GenAI I.pdf\n",
      "- ownstream tasks. Frontier models represent the most advanced and powerful  foundation models, pushing the boundaries of AI capabilities at any given time. AI Model Taxonomy: Openness 1 Closed-Source Models Proprietary models where weights, inference code, and training data remain confidential. Access is typically via  API, and internal workings are\n"
     ]
    }
   ],
   "source": [
    "def synthesize_passages(indices, chunks, max_chars=1200):\n",
    "    synthesis = []\n",
    "    used_sources = set()\n",
    "\n",
    "    for idx in indices:\n",
    "        source = chunks[idx][\"metadata\"][\"source\"]\n",
    "        text = chunks[idx][\"page_content\"].replace(\"\\n\", \" \")\n",
    "\n",
    "        if source not in used_sources:\n",
    "            synthesis.append(f\"\\nSource: {source}\")\n",
    "            used_sources.add(source)\n",
    "\n",
    "        synthesis.append(f\"- {text[:350]}\")\n",
    "\n",
    "        if sum(len(s) for s in synthesis) > max_chars:\n",
    "            break\n",
    "\n",
    "    return \"\\n\".join(synthesis)\n",
    "\n",
    "\n",
    "# Use indices from Step 5\n",
    "synthesis_output = synthesize_passages(top_indices, chunks)\n",
    "\n",
    "print(\"üß† Synthesized Knowledge:\")\n",
    "print(synthesis_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6711c696-6175-495a-9f36-81031249d2c3",
   "metadata": {},
   "source": [
    "## LLM-based Question Answering (Jupyter Notebook Interface)\r\n",
    "\r\n",
    "In this step, the Jupyter Notebook acts as the interactive interface where users\r\n",
    "can ask natural-language questions about uploaded PDF documents. Retrieved\r\n",
    "passages are passed as context to a locally hosted large language model (LLaMA 3\r\n",
    "via Ollama), which generates answers grounded in the document content.\r\n",
    "nteractively.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ec5891d-711d-4b11-80d5-7dfd41bf09bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Answer from LLM:\n",
      "\n",
      "Attention in Transformers refers to the ability of tokens within an input sequence to \"pay attention\" to each other, determining how much influence each token should have on the representation of every other token. This is achieved by computing attention weights using the softmax function and multiplying them with a Value matrix, allowing for contextual understanding and capturing long-range dependencies in the input sequence.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "OLLAMA_PATH = r\"C:\\Users\\PC\\AppData\\Local\\Programs\\Ollama\\ollama.exe\"\n",
    "\n",
    "def ask_pdf_llm(question, top_indices, chunks):\n",
    "    \"\"\"\n",
    "    Ask a question about the PDFs using a local LLM.\n",
    "    The Jupyter Notebook serves as the user interface.\n",
    "    \"\"\"\n",
    "\n",
    "    # Build context from retrieved chunks\n",
    "    context = \"\\n\".join(\n",
    "        chunks[idx][\"page_content\"][:300].replace(\"\\n\", \" \")\n",
    "        for idx in top_indices\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a helpful academic assistant.\n",
    "\n",
    "    Answer the question clearly and concisely using ONLY the context below.\n",
    "    Do not repeat sentences.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question:\n",
    "    {question}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    # ‚úÖ FORCE UTF-8 ENCODING (FIXES Windows error)\n",
    "    result = subprocess.run(\n",
    "        [OLLAMA_PATH, \"run\", \"llama3\"],\n",
    "        input=prompt.encode(\"utf-8\"),\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE\n",
    "    )\n",
    "\n",
    "    return result.stdout.decode(\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Notebook-based User Interface\n",
    "# ===============================\n",
    "\n",
    "user_question = \"What is attention in transformers?\"\n",
    "\n",
    "answer = ask_pdf_llm(user_question, top_indices, chunks)\n",
    "\n",
    "print(\"üß† Answer from LLM:\\n\")\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc139ac-1a28-4da4-bd69-427a85397b7b",
   "metadata": {},
   "source": [
    "## Interactive Question Answering Loop\r\n",
    "\r\n",
    "In this step, the system provides an interactive command-line style interface within the\r\n",
    "Jupyter Notebook. Users can repeatedly ask natural language questions about the uploaded\r\n",
    "PDF documents.\r\n",
    "\r\n",
    "For each question:\r\n",
    "- The system retrieves relevant text passages from the document chunks.\r\n",
    "- These passages are passed as context to the local Large Language Model.\r\n",
    "- The model generates an answer strictly grounded in the document content.\r\n",
    "\r\n",
    "The interaction continues until the user types **\"exit\"**, allowing flexible and iterative\r\n",
    "exploration of the document collection.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49df2255-667a-48a6-b63b-0af69e2fd1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùì Ask a question (or type 'exit'):  exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß† Answer:\n",
      "\n",
      "The attention mechanism in the transformer model is designed to capture context by determining how much each token should influence the representation of every other token within the input sequence. This is achieved through the computation of attention weights, which are calculated using the softmax function and dot product of queries, keys, and values. The goal is to scale the dot product to avoid unstable gradient flow and create a normalized embedding that represents how much each token should influence the representation of others.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def ask_questions():\n",
    "    while True:\n",
    "        question = input(\"\\n‚ùì Ask a question (or type 'exit'): \")\n",
    "        if question.lower() == \"exit\":\n",
    "            print(\"üëã Session ended.\")\n",
    "            break\n",
    "\n",
    "        answer = ask_pdf_llm(question, top_indices, chunks)\n",
    "        print(\"\\nüß† Answer:\\n\")\n",
    "        print(answer)\n",
    "\n",
    "ask_questions()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c5c7f3-a87d-47b1-9afd-b31874ca0521",
   "metadata": {},
   "source": [
    "## Demonstration Application (Optional)\r\n",
    "\r\n",
    "In addition to the Jupyter Notebook interface, we implemented a lightweight\r\n",
    "demonstration web application to showcase the core functionality of the system\r\n",
    "in a more user-facing form.\r\n",
    "\r\n",
    "The purpose of this demo app is **not** to replace the notebook, but to:\r\n",
    "- Illustrate how the same retrieval and synthesis pipeline can be deployed in\r\n",
    "  an interactive application.\r\n",
    "- Allow users to upload PDFs and ask questions through a simple web interface.\r\n",
    "- Demonstrate that the system design is modular and transferable beyond\r\n",
    "  exploratory notebooks.\r\n",
    "\r\n",
    "The demo application uses the same underlying steps as the notebook:\r\n",
    "1. PDF loading and text extraction\r\n",
    "2. Document chunking\r\n",
    "3. Semantic retrieval using TF-IDF and cosine similarity\r\n",
    "4. Context-grounded answer generation\r\n",
    "\r\n",
    "This additional interface is provided to improve understanding of the system‚Äôs\r\n",
    "practical applicability and is intended purely as a **demonstration artifact**.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c331de1-03fb-4e1e-8beb-b7fc6cbfb76a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
